{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src='images/logo.jpg' width='300px'>\n",
    "<h2> Chương 5: THEO VẾT VÀ NHẬN DẠNG ĐỐI TƯỢNG</h2>\n",
    "</center>\n",
    "\n",
    "---\n",
    "\n",
    "A. Theo vết đối tượng:\n",
    "Trong thị giác máy tính có 2 bài toán phổ biến:\n",
    "\n",
    "* Phát hiện đối tượng - Object detection (OD) – Làm việc trên một khung hình (frame) \n",
    "* Theo vết đối tượng - Object tracking (OT) – Làm việc trên nhiều khung hình liên tiếp\n",
    "\n",
    "Mục tiêu của Video Object tracking là xác định vị trí của một hoặc nhiều đối tượng (target) trong các frame liên tiếp của Video\n",
    "* Single Object tracking (SOT) – Chỉ có một object được theo dõi ngay cả khi môi trường có nhiều  đối tượng.\n",
    "* Muiltiple Object tracking (OT) – Nhiều đối tượng được theo dõi theo thời gian, thậm chí nó có thể theo dõi các đối tượng mới xuất hiện trong video.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Làm việc với Video\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gọi thư viện:\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Đọc video từ webcam và từ file \n",
    "#Kết nối webcam \n",
    "#cap = cv2.VideoCapture(0)\n",
    "\n",
    "cap = cv2.VideoCapture(\"Video/slow_traffic_small.mp4\")\n",
    "if not cap.isOpened(): \n",
    "    print(\"Ko kết nối được với cam\")\n",
    "    exit()\n",
    "#Hiển thị \n",
    "while True:\n",
    "    #Đọc từng frame trong video \n",
    "    rec,frame = cap.read()\n",
    "\n",
    "    cv2.imshow('Video WebCam',frame)\n",
    "    #Thoát chế độ video \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "#Giải phóng bộ nhớ \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tách lưu từng frame trong video: \n",
    "\n",
    "folder = 'Frames_output/'\n",
    "count = 0 \n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened(): \n",
    "    print(\"Ko kết nối được với cam\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "#Hiển thị \n",
    "while True:\n",
    "    #Đọc từng frame trong video \n",
    "    rec,frame = cap.read()\n",
    "    \n",
    "    #Lưu các frame vào thư mục nhất định\n",
    "    filename = folder + 'Frame_' + str(count) + '.jpg'\n",
    "    cv2.imwrite(filename,frame)\n",
    "    count += 1 \n",
    "    \n",
    "\n",
    "    \n",
    "    cv2.imshow('Video WebCam',frame)\n",
    "    #Thoát chế độ video \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    \n",
    "\n",
    "#Giải phóng bộ nhớ \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lưu video ra file\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened(): \n",
    "    print(\"Ko kết nối được với cam\")\n",
    "    exit()\n",
    "\n",
    "#Thiết lập tham số ghi file Video:\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) + 0.5)\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) + 0.5)\n",
    "size = (width, height)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "out = cv2.VideoWriter('Result_object.mp4', fourcc, 20.0, size)\n",
    "\n",
    "\n",
    "#Hiển thị \n",
    "while True:\n",
    "    #Đọc từng frame trong video \n",
    "    rec,frame = cap.read()\n",
    "    \n",
    "    cv2.imshow('Video WebCam',frame)\n",
    "    out.write(frame)\n",
    "    #Thoát chế độ video \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "\n",
    "out.release()\n",
    "#Giải phóng bộ nhớ \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Một số phương pháp theo vết đối tượng\n",
    "## 2.1 Optical Flow\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link tham khảo về optical flow:\n",
    "\n",
    "https://nanonets.com/blog/optical-flow/\n",
    "\n",
    "https://docs.opencv.org/master/d4/dee/tutorial_optical_flow.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Sparse Optical Flow\n",
    "---\n",
    "https://docs.opencv.org/3.4/d4/dee/tutorial_optical_flow.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Đọc video\n",
    "cap = cv2.VideoCapture(\"Video/slow_traffic_small.mp4\")\n",
    "\n",
    "cv2.startWindowThread()\n",
    "# params for ShiTomasi corner detection\n",
    "st_params  = dict(maxCorners = 100, \n",
    "                  qualityLevel = 0.3,\n",
    "                  minDistance = 7,\n",
    "                  blockSize = 7)\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict(winSize  = (15,15),\n",
    "                 maxLevel = 2,\n",
    "                 criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10, 0.03))\n",
    "\n",
    "# Create some random colors\n",
    "color = np.random.randint(0,255,(100,3))\n",
    "\n",
    "# Take first frame and find corners in it\n",
    "ret, old_frame = cap.read()\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **st_params)\n",
    "# Create a mask image for drawing purposes\n",
    "mask = np.zeros_like(old_frame)\n",
    "\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "  \n",
    "    # calculate optical flow\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "    \n",
    "    # Select good points\n",
    "    if p1 is not None:\n",
    "        good_new = p1[st==1]\n",
    "        good_old = p0[st==1]\n",
    "    \n",
    "    # draw the tracks\n",
    "    for i,(new,old) in enumerate(zip(good_new, good_old)):\n",
    "        a,b = new.ravel()\n",
    "        c,d = old.ravel()\n",
    "        mask = cv2.line(mask, (int(a),int(b)),(int(c),int(d)), color[i].tolist(), 2)\n",
    "        frame = cv2.circle(frame,(int(a),int(b)),5,color[i].tolist(),-1)\n",
    "    img = cv2.add(frame,mask)\n",
    "    cv2.imshow('Optical flow',img)\n",
    "    \n",
    "    \n",
    "    if cv2.waitKey(300) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "    # Now update the previous frame and previous points\n",
    "    old_gray = frame_gray.copy()\n",
    "    p0 = good_new.reshape(-1,1,2)\n",
    "    \n",
    "# Giải phóng bộ nhớ:\n",
    "cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()    \n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Dense Optical Flow\n",
    "---\n",
    "Link tham khảo:\n",
    "    \n",
    "https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_video/py_lucas_kanade/py_lucas_kanade.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import Libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Đọc video:\n",
    "cap = cv2.VideoCapture(\"Video/slow_traffic_small.mp4\")\n",
    "\n",
    "# Read the capture and get the first frame\n",
    "ret,first_frame = cap.read()\n",
    "\n",
    "# Convert frame to Grayscale\n",
    "prev_gray = cv2.cvtColor(first_frame,\n",
    "                        cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Create# Create an image with the same dimensions as the frame for later drawing purposes\n",
    "mask = np.zeros_like(first_frame)\n",
    "\n",
    "# Saturation to maximum\n",
    "mask[...,1] = 255\n",
    "\n",
    "# While loop\n",
    "while True:\n",
    "\n",
    "    # Read the capture and get the first frame\n",
    "    ret,frame = cap.read()\n",
    "    \n",
    "    # Open new window and display the input frame\n",
    "    cv2.imshow(\"input\",frame)\n",
    "    \n",
    "    # Convert all frame to Grayscale (previously we did only the first frame)\n",
    "    gray = cv2.cvtColor(frame,\n",
    "                       cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calculate dense optical flow by Farneback\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev_gray,\n",
    "                                       gray,\n",
    "                                        None,\n",
    "                                        0.5,\n",
    "                                        3,15,3,5,1.2,0\n",
    "                                       )\n",
    "    \n",
    "    # Compute Magnitude and Angle\n",
    "    magn,angle = cv2.cartToPolar(flow[...,0],\n",
    "                                 flow[...,1])\n",
    "    \n",
    "    # Set image hue depanding on the optical flow direction\n",
    "    mask[...,0] = angle*180/np.pi/2    \n",
    "        \n",
    "    # Normalize the magnitude\n",
    "    mask[...,2] = cv2.normalize(magn,\n",
    "                                None,\n",
    "                                0,\n",
    "                                255,\n",
    "                                cv2.NORM_MINMAX)\n",
    "    \n",
    "    # Convert HSV to RGB\n",
    "    rgb = cv2.cvtColor(mask,cv2.COLOR_HSV2RGB)\n",
    "    \n",
    "    # Open new window and display the output\n",
    "    cv2.imshow(\"Dense Optical Flow\",rgb)\n",
    "    \n",
    "    # Update previous frame\n",
    "    prev_gray = gray\n",
    "    \n",
    "    # Close the frame\n",
    "    if cv2.waitKey(10) & 0XFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "# Release and Destroy\n",
    "cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2: MeanShift - CamShift\n",
    "---\n",
    "Link tham khảo:\n",
    "\n",
    "https://docs.opencv.org/master/d7/d00/tutorial_meanshift.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. MeanShift\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read video\n",
    "cap = cv2.VideoCapture(\"Video/slow_traffic_small.mp4\")\n",
    "\n",
    "# take first frame of the video\n",
    "ret,frame = cap.read()\n",
    "\n",
    "# setup initial location of window\n",
    "x, y, w, h = 300, 200, 100, 50 # simply hardcoded the values\n",
    "track_window = (x, y, w, h)\n",
    "\n",
    "# set up the ROI for tracking\n",
    "roi = frame[y:y+h, x:x+w]\n",
    "hsv_roi =  cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "mask = cv2.inRange(hsv_roi, np.array((0., 60.,32.)), np.array((180.,255.,255.)))\n",
    "roi_hist = cv2.calcHist([hsv_roi],[0],mask,[180],[0,180])\n",
    "cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n",
    "\n",
    "# Setup the termination criteria, either 10 iteration or move by atleast 1 pt\n",
    "term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        dst = cv2.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n",
    "        \n",
    "        # apply meanshift to get the new location\n",
    "        ret, track_window = cv2.meanShift(dst, track_window, term_crit)\n",
    "        \n",
    "        # Draw it on image\n",
    "        x,y,w,h = track_window\n",
    "        img2 = cv2.rectangle(frame, (x,y), (x+w,y+h), 255,2)\n",
    "        cv2.imshow('Example MeanShift',img2)\n",
    "        if cv2.waitKey(300) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "#Giải phóng bộ nhớ\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Camshift\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nviet\\AppData\\Local\\Temp\\ipykernel_27964\\3458440909.py:30: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  pts = np.int0(pts)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read video\n",
    "cap = cv2.VideoCapture(\"Video/slow_traffic_small.mp4\")\n",
    "\n",
    "# take first frame of the video\n",
    "ret,frame = cap.read()\n",
    "\n",
    "# setup initial location of window\n",
    "x, y, w, h = 300, 200, 100, 50 # simply hardcoded the values\n",
    "track_window = (x, y, w, h)\n",
    "\n",
    "# set up the ROI for tracking\n",
    "roi = frame[y:y+h, x:x+w]\n",
    "hsv_roi =  cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "mask = cv2.inRange(hsv_roi, np.array((0., 60.,32.)), np.array((180.,255.,255.)))\n",
    "roi_hist = cv2.calcHist([hsv_roi],[0],mask,[180],[0,180])\n",
    "cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n",
    "\n",
    "# Setup the termination criteria, either 10 iteration or move by atleast 1 pt\n",
    "term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        dst = cv2.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n",
    "        \n",
    "        # apply camshift to get the new location\n",
    "        ret, track_window = cv2.CamShift(dst, track_window, term_crit)\n",
    "        # Draw it on image\n",
    "        pts = cv2.boxPoints(ret)\n",
    "        pts = np.int0(pts)\n",
    "        img2 = cv2.polylines(frame,[pts],True, 255,2)\n",
    "        cv2.imshow('Example CamShift',img2)\n",
    "        if cv2.waitKey(300) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "#Giải phóng bộ nhớ:\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Ví dụ : Theo vết một đối tượng trong Video (Single Object Tracking)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version OpenCV: 4.11.0\n"
     ]
    }
   ],
   "source": [
    "#Import Libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "print('Version OpenCV:',cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Capture the Video\n",
    "cap = cv2.VideoCapture('Video/crime-object.mp4')\n",
    "\n",
    "# Tracker sử dụng OpenCV:\n",
    "tracker = cv2.TrackerCSRT_create() #CamShift\n",
    "#tracker=cv2.TrackerMIL_create()     #MeanShift\n",
    "\n",
    "# Đọc frame đầu tiên:\n",
    "ret,frame = cap.read()\n",
    "\n",
    "#Thiết lập tham số ghi file Video:\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) + 0.5)\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) + 0.5)\n",
    "size = (width, height)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('Result_object.mp4', fourcc, 20.0, size)\n",
    "\n",
    "\n",
    "# Select our ROI\n",
    "roi = cv2.selectROI(frame,False)\n",
    "\n",
    "# Initialize tracker\n",
    "ret = tracker.init(frame,roi)\n",
    "\n",
    "while True:\n",
    "    # Read the capture\n",
    "    ret,frame = cap.read()\n",
    "    \n",
    "    # update tracker\n",
    "    success, roi = tracker.update(frame)\n",
    "    \n",
    "    # roi -> from tuple to int\n",
    "    (x,y,w,h)=tuple(map(int,roi))\n",
    "    \n",
    "    # Draw rects as tracker moves\n",
    "    if success:\n",
    "        \n",
    "        # Sucess on tracking\n",
    "        pts1=(x,y)\n",
    "        pts2=(x+w,y+h)\n",
    "        cv2.rectangle(frame,pts1,pts2,(255,10,55),3)\n",
    "        cv2.putText(frame,'Object',pts1,\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),2)\n",
    "    # else\n",
    "    else:\n",
    "    \n",
    "        # Failure on tracking\n",
    "        cv2.putText(frame,'Fail to track the object',(150,200),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,1,(25,125,255),2)\n",
    "        \n",
    "    # Display Tracker\n",
    "    cv2.putText(frame,\n",
    "                \"FIT.HUMG\",\n",
    "                (20,40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,1,\n",
    "                (255,255,0),3)\n",
    "    \n",
    "    # Hiển thị kết quả theo vết và lưu ra file .mp4\n",
    "    cv2.imshow(\"Demo Object Tracking\",frame)    \n",
    "    out.write(frame)\n",
    "        \n",
    "        \n",
    "    # Exit with q button\n",
    "    if cv2.waitKey(10) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "    \n",
    "    \n",
    "# Giải phóng bộ nhớ:\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Capture the Video\n",
    "cap = cv2.VideoCapture('Video/crime-object.mp4')\n",
    "\n",
    "# Tracker sử dụng OpenCV:\n",
    "# tracker = cv2.TrackerCSRT_create() #CamShift\n",
    "tracker=cv2.TrackerMIL_create()     #MeanShift\n",
    "\n",
    "# Đọc frame đầu tiên:\n",
    "ret,frame = cap.read()\n",
    "\n",
    "#Thiết lập tham số ghi file Video:\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) + 0.5)\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) + 0.5)\n",
    "size = (width, height)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('Result_object.mp4', fourcc, 20.0, size)\n",
    "\n",
    "\n",
    "# Select our ROI\n",
    "roi = cv2.selectROI(frame,False)\n",
    "\n",
    "# Initialize tracker\n",
    "ret = tracker.init(frame,roi)\n",
    "\n",
    "while True:\n",
    "    # Read the capture\n",
    "    ret,frame = cap.read()\n",
    "    \n",
    "    # update tracker\n",
    "    success, roi = tracker.update(frame)\n",
    "    \n",
    "    # roi -> from tuple to int\n",
    "    (x,y,w,h)=tuple(map(int,roi))\n",
    "    \n",
    "    # Draw rects as tracker moves\n",
    "    if success:\n",
    "        \n",
    "        # Sucess on tracking\n",
    "        pts1=(x,y)\n",
    "        pts2=(x+w,y+h)\n",
    "        cv2.rectangle(frame,pts1,pts2,(255,10,55),3)\n",
    "        cv2.putText(frame,'Object',pts1,\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),2)\n",
    "    # else\n",
    "    else:\n",
    "    \n",
    "        # Failure on tracking\n",
    "        cv2.putText(frame,'Fail to track the object',(150,200),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,1,(25,125,255),2)\n",
    "        \n",
    "    # Display Tracker\n",
    "    cv2.putText(frame,\n",
    "                \"FIT.HUMG\",\n",
    "                (20,40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,1,\n",
    "                (255,255,0),3)\n",
    "    \n",
    "    # Hiển thị kết quả theo vết và lưu ra file .mp4\n",
    "    cv2.imshow(\"Demo Object Tracking\",frame)    \n",
    "    out.write(frame)\n",
    "        \n",
    "        \n",
    "    # Exit with q button\n",
    "    if cv2.waitKey(10) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "    \n",
    "    \n",
    "# Giải phóng bộ nhớ:\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
